# SentimentFlow-V2

## Overview

**SentimentFlow-V2** is an end-to-end **Data Engineering + NLP pipeline** that autonomously gathers and analyzes news sentiment for a curated list of startups.

It performs a **daily ‚Äúsync‚Äù** by fetching global articles, identifying startups mentioned, performing **zero-shot sentiment analysis** per startup, and storing results in a PostgreSQL database.  
A **Streamlit-based Admin Dashboard** allows easy management of tracked startups and sectors.

This repository demonstrates a real-world, production-grade application of **Data Science, NLP, and CI/CD automation**.

---

## Tech Stack

| Layer | Technology | Purpose |
| :-- | :-- | :-- |
| **Language** | Python 3.11 | Core logic & scripting |
| **Database** | PostgreSQL | Relational data storage (via Prisma Proxy) |
| **Data Fetching** | NewsAPI | Source for global news articles |
| **ML Model** | [Soumil24/zero-shot-startup-sentiment-v2](https://huggingface.co/Soumil24/zero-shot-startup-sentiment-v2) | Zero-Shot NLI model for startup sentiment |
| **NLP Libraries** | `transformers`, `torch` | Model inference |
| **Core Libraries** | `psycopg2`, `pyahocorasick` | DB connection & high-speed text matching |
| **Admin UI** | Streamlit | Web-based admin dashboard |
| **Automation** | GitHub Actions | Scheduled ETL runs (3√ó daily) |

---

##  Core Features

**Automated 3√ó/Day Pipeline** ‚Äî runs automatically via GitHub Actions.  
**Dynamic Fetch Logic** ‚Äî 30-day *backfill* for new startups, 1-day *maintenance* fetch for existing ones.  
**Keyword-Driven Queries** ‚Äî auto-builds NewsAPI queries using `findingKeywords` (e.g., ‚Äúfood delivery‚Äù).  
**High-Performance Search** ‚Äî Aho-Corasick automaton detects 30+ startups in a single text pass.  
**Bulk AI Analysis** ‚Äî Zero-Shot sentiment inference in mini-batches for GPU efficiency.  
**Streamlit Admin Dashboard** ‚Äî add/update startups directly through the browser.  
**Transactional Integrity** ‚Äî all DB operations occur in atomic transactions.

---

## Project Structure

```
/
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ ‚îî‚îÄ‚îÄ main_pipeline.yml # CI/CD pipeline (GitHub Actions)
‚îú‚îÄ‚îÄ scripts/
‚îÇ ‚îú‚îÄ‚îÄ clear_data.py # Clears Articles & Sentiment tables
‚îÇ ‚îî‚îÄ‚îÄ seed_sectors.py # Seeds 'Sector' table with 30 sectors
‚îú‚îÄ‚îÄ src/
‚îÇ ‚îú‚îÄ‚îÄ core/
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ config.py # Loads environment (.env)
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ logger.py # Project-wide logging setup
‚îÇ ‚îú‚îÄ‚îÄ constants.py # Global constants (batch size, etc.)
‚îÇ ‚îú‚îÄ‚îÄ pipeline/
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ init.py # Main ETL pipeline orchestrator
‚îÇ ‚îî‚îÄ‚îÄ utils/
‚îÇ ‚îú‚îÄ‚îÄ api_utils.py # NewsAPI calls, key rotation, dedup
‚îÇ ‚îú‚îÄ‚îÄ db_utils.py # DB connections, inserts, queries
‚îÇ ‚îú‚îÄ‚îÄ sentiment_utils.py # Zero-shot model & batch predictions
‚îÇ ‚îî‚îÄ‚îÄ text_utils.py # Aho-Corasick search engine & IDs
‚îú‚îÄ‚îÄ .env.example # Template for environment variables
‚îú‚îÄ‚îÄ main.py # Entry point for the pipeline
‚îú‚îÄ‚îÄ requirements.txt # Python dependencies
‚îî‚îÄ‚îÄ streamlit_admin.py # Streamlit admin dashboard
```

---

## Database Design

A **4-table relational model** efficiently links startups to articles and sentiments.

### Sector Table

| Column | Type | Description |
| :-- | :-- | :-- |
| `id` | INT (PK) | Unique sector ID (e.g., 1, 2) |
| `name` | TEXT | Sector name (e.g., ‚ÄúFintech‚Äù) |

### Startups Table

| Column | Type | Description |
| :-- | :-- | :-- |
| `id` | TEXT (PK) | Deterministic ID (e.g., `swiggy-a1b2c3-d4e5`) |
| `name` | TEXT | Startup‚Äôs official name |
| `sectorId` | INT (FK) | Links to `Sector.id` |
| `description` | TEXT | Startup description |
| `imageUrl` | TEXT | Logo URL |
| `findingKeywords` | TEXT | JSON string of keywords (e.g., `["food delivery"]`) |

### Articles Table

| Column | Type | Description |
| :-- | :-- | :-- |
| `id` | UUID (PK) | Unique article ID |
| `title` | TEXT | Article title |
| `content` | TEXT | Truncated content (‚â§ 300 chars) |
| `url` | TEXT (UNIQUE) | Article URL |
| `publishedAt` | TIMESTAMP | Original publication time |

### ArticlesSentiment Table (Many-to-Many)

| Column | Type | Description |
| :-- | :-- | :-- |
| `id` | UUID (PK) | Unique entry ID |
| `articleId` | UUID (FK) | Links to `Articles.id` |
| `startupId` | TEXT (FK) | Links to `Startups.id` |
| `positiveScore` | FLOAT | Probability of positive sentiment |
| `negativeScore` | FLOAT | Probability of negative sentiment |
| `neutralScore` | FLOAT | Probability of neutral sentiment |
| `sentiment` | TEXT | Final label (`positive` / `neutral` / `negative`) |

---

## Sentiment Analysis Logic

The project uses a **Zero-Shot Natural Language Inference (NLI)** model ‚Äî not a conventional sentiment classifier ‚Äî allowing startup-specific sentiment detection even in multi-company articles.

**Model:** [`Soumil24/zero-shot-startup-sentiment-v2`](https://huggingface.co/Soumil24/zero-shot-startup-sentiment-v2)

**Premise:**  
> ‚ÄúSwiggy‚Äôs revenue jumps, but Zomato‚Äôs losses widen‚Ä¶‚Äù

**Hypotheses per startup:**  
1. The news for Swiggy is **positive**.  
2. The news for Swiggy is **neutral**.  
3. The news for Swiggy is **negative**.

The model outputs **entailment probabilities** for each hypothesis:  
‚Üí `positiveScore`, `neutralScore`, `negativeScore`  
‚Üí the label with the highest score becomes the **final sentiment**.

---

## Getting Started

### 1 Clone the Repository
```bash
git clone https://github.com/SoumilMalik24/SentimentFlow-V2.git
cd SentimentFlow-V2
```

### 2 Create Virtual Environment
```bash
python -m venv venv
# Linux/Mac
source venv/bin/activate
# Windows
.\venv\Scripts\activate
```

### 3 Install Dependencies
```bash
pip install -r requirements.txt
```

### 4 Configure Environment

Copy .env.example ‚Üí .env, then fill in:
```bash
DB_URL=postgresql://user:pass@host:port/dbname
NEWS_API_KEYS=["key1","key2"]
HF_TOKEN=your_huggingface_token
MODEL_PATH=Soumil24/zero-shot-startup-sentiment-v2
```

---

## Running the Project

### 1. Admin Dashboard (setup first)

Used to manage sectors & startups.

**Seed sectors:**
```bash
python scripts/seed_sectors.py
```

**Launch the Streamlit app:**
```bash
streamlit run streamlit_admin.py
```
streamlit run streamlit_admin.py

---

### 2. Main Pipeline

Runs the automated ETL workflow (fetch ‚Üí analyze ‚Üí store).

**Manual run:**
```bash
python main.py
```
**To force a full reset (clear all data):**
```bash
python scripts/clear_data.py
```

---

# CI/CD Automation

Configured to run automatically via **GitHub Actions**.

| Setting | Description |
| :-- | :-- |
| **Workflow File** | `.github/workflows/main_pipeline.yml` |
| **Schedule** | Runs 3√ó per day ‚Äî 7 AM, 1 PM, and 7 PM (IST) |
| **Secrets Required** | `DB_URL`, `NEWS_API_KEYS`, `HF_TOKEN`, `MODEL_PATH` |

---

## Contributors

**Soumil Malik** ‚Äî Developer  
üîó [GitHub @SoumilMalik24](https://github.com/SoumilMalik24)  

Creator of the [Zero-Shot Startup Sentiment Model](https://huggingface.co/Soumil24/zero-shot-startup-sentiment-v2)

---

## License

This project is released under the **MIT License**.  
Feel free to **fork**, **adapt**, and **build upon it** ‚Äî credit is appreciated!

---

## Inspiration

**SentimentFlow-V2** was built to bridge the gap between **real-time news analysis** and **startup intelligence**, providing **automated**, **explainable**, and **scalable sentiment insights** for **investors**, **analysts**, and **researchers**.
